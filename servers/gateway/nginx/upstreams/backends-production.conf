# ============================================================================
# Upstream Backend Configuration - PRODUCTION
# ============================================================================
# Production-grade load balancing configuration for InsightSerenity Platform
# Supports 5 admin server instances and 5 customer service instances
# ============================================================================

# ==========================================================================
# Admin Backend Pool (5 instances) - Weighted Round Robin
# ==========================================================================
upstream admin_backend {
    # Shared memory zone for tracking upstream metrics
    zone admin_backend 64k;

    # Load balancing algorithm: Weighted round-robin
    # Distributes requests based on server weights

    # Primary admin servers (high capacity)
    server 10.0.2.10:3002 weight=100 max_fails=3 fail_timeout=30s max_conns=1000;
    server 10.0.2.11:3002 weight=100 max_fails=3 fail_timeout=30s max_conns=1000;
    server 10.0.2.12:3002 weight=100 max_fails=3 fail_timeout=30s max_conns=1000;

    # Secondary admin servers (medium capacity)
    server 10.0.2.13:3002 weight=75  max_fails=3 fail_timeout=30s max_conns=800;
    server 10.0.2.14:3002 weight=75  max_fails=3 fail_timeout=30s max_conns=800;

    # Connection pooling for performance
    keepalive 128;               # Maintain 128 idle keepalive connections
    keepalive_requests 1000;     # Max requests per keepalive connection
    keepalive_timeout 120s;      # Keep connections alive for 2 minutes

    # Health check parameters (passive)
    # max_fails=3: Mark server down after 3 consecutive failures
    # fail_timeout=30s: Wait 30s before retrying failed server
    # max_conns=1000: Limit concurrent connections per server
}

# ==========================================================================
# Customer Services Backend Pool (5 instances) - Least Connections
# ==========================================================================
upstream customer_backend {
    # Shared memory zone for tracking upstream metrics
    zone customer_backend 128k;

    # Load balancing algorithm: Least connections
    # Routes requests to server with fewest active connections
    # Optimal for variable request processing times
    least_conn;

    # Customer service instances
    server 10.0.3.10:3001 max_fails=3 fail_timeout=20s max_conns=1500;
    server 10.0.3.11:3001 max_fails=3 fail_timeout=20s max_conns=1500;
    server 10.0.3.12:3001 max_fails=3 fail_timeout=20s max_conns=1500;
    server 10.0.3.13:3001 max_fails=3 fail_timeout=20s max_conns=1500;
    server 10.0.3.14:3001 max_fails=3 fail_timeout=20s max_conns=1500;

    # Connection pooling for performance
    keepalive 256;               # Higher keepalive for customer services
    keepalive_requests 1000;
    keepalive_timeout 120s;
}

# ==========================================================================
# WebSocket Backend Pool - IP Hash (Sticky Sessions)
# ==========================================================================
upstream websocket_backend {
    # Shared memory zone
    zone websocket_backend 64k;

    # Load balancing algorithm: IP hash
    # Ensures same client always connects to same server
    # Required for WebSocket persistent connections
    ip_hash;

    # WebSocket endpoints (same as customer services)
    server 10.0.3.10:3001 max_fails=2 fail_timeout=30s;
    server 10.0.3.11:3001 max_fails=2 fail_timeout=30s;
    server 10.0.3.12:3001 max_fails=2 fail_timeout=30s;
    server 10.0.3.13:3001 max_fails=2 fail_timeout=30s;
    server 10.0.3.14:3001 max_fails=2 fail_timeout=30s;

    # Longer keepalive for WebSocket connections
    keepalive 64;
    keepalive_timeout 300s;      # 5 minutes for WebSocket
}

# ==========================================================================
# Backup/Failover Servers (Optional)
# ==========================================================================
# Uncomment to add backup servers that only receive traffic when all
# primary servers are down

# upstream admin_backend_backup {
#     server 10.0.2.100:3002 backup;
#     server 10.0.2.101:3002 backup;
# }

# ==========================================================================
# Health Check Configuration (NGINX Plus)
# ==========================================================================
# For NGINX Plus, enable active health checks:
#
# upstream admin_backend {
#     server 10.0.2.10:3002;
#     server 10.0.2.11:3002;
#     # ... more servers
#
#     # Active health check
#     health_check interval=10s fails=3 passes=2 uri=/health match=server_ok;
# }
#
# match server_ok {
#     status 200;
#     body ~ "healthy";
# }

# ==========================================================================
# Performance Notes
# ==========================================================================
# - Admin Backend: 5 servers @ 3002, max 4,550 concurrent connections
# - Customer Backend: 5 servers @ 3001, max 7,500 concurrent connections
# - Total capacity: ~12,000 concurrent connections
# - Expected throughput: 50,000+ requests/second
# - Automatic failover: < 30 seconds
# - Connection reuse reduces latency by 80%
